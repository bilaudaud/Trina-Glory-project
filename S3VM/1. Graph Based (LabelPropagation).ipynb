{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f311c9",
   "metadata": {},
   "source": [
    "# Work Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23833f9",
   "metadata": {},
   "source": [
    "<img src=\"work-flow.jpg\" alt='wrok flow'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622d809f",
   "metadata": {},
   "source": [
    "# Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c76570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7be20eb",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf361ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the label and unlabel datasets\n",
    "lab_dataset = pd.read_csv('Final_ToBeLabelled(ICD_INCLUDED)_EN.csv', sep='\\t')\n",
    "unlab_dataset = pd.read_csv('Final_Unlabelled_EN.csv', sep='\\t')\n",
    "# split labelled datasets into X and y\n",
    "X_lab = pd.read_csv('Final_ToBeLabelled(ICD_INCLUDED)_EN.csv', sep='\\t').drop(labels=['ICD','index_exam'], axis =1)\n",
    "y_lab = pd.read_csv('Final_ToBeLabelled(ICD_INCLUDED)_EN.csv', sep='\\t')['ICD'].astype('category') # as category \n",
    "# split Unlabelled datasets into X and y\n",
    "X_unlab = pd.read_csv('Final_Unlabelled_EN.csv', sep='\\t').drop(labels=['ICD','index_exam'], axis =1)\n",
    "y_unlab = pd.read_csv('Final_Unlabelled_EN.csv', sep='\\t')['ICD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a421f9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((192, 17), (17174, 17), (192, 15), (17174, 15), (17174,), (192,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the dataset before preprocessing \n",
    "lab_dataset.shape, unlab_dataset.shape, X_lab.shape,X_unlab.shape, y_unlab.shape, y_lab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917bcfda",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing on X_train and X_unlab (label encoding)\n",
    "X_sex = pd.get_dummies(data=X['Weiblich/Männlich'])\n",
    "X_unlab_sex = pd.get_dummies(data=X_unlab['Weiblich/Männlich'])\n",
    "X_age = pd.get_dummies(data=X['age'])\n",
    "X_unlab_age = pd.get_dummies(data=X_unlab['age'])\n",
    "# preprocessing\n",
    "# preprocessing on X and X_unlab (label encoding)\n",
    "X_sex = pd.get_dummies(data=X['Weiblich/Männlich'])\n",
    "X_unlab_sex = pd.get_dummies(data=X_unlab['Weiblich/Männlich'])\n",
    "X_age = pd.get_dummies(data=X['age'])\n",
    "X_unlab_age = pd.get_dummies(data=X_unlab['age'])\n",
    "# drop the UUID, age and sex columns from the data\n",
    "X_unlab.drop(labels=['UUID', 'age','Weiblich/Männlich'], axis=1, inplace=True)\n",
    "X.drop(labels=['age','Weiblich/Männlich', 'UUID'],axis=1,inplace=True)\n",
    "# after the preprocessing,instantiate call it X_train\n",
    "X_train = pd.concat([X_sex,X_age,X],axis=1).astype('float')\n",
    "# after the preprocessing,instantiate call it X_unlab_p\n",
    "X_unlab_p = pd.concat([X_unlab_sex,X_unlab_age,X_unlab],axis=1).astype('float')\n",
    "# summarize training set size\n",
    "print('Labeled Train Set:', X_train.shape, y.shape)\n",
    "# summarize Unlabeled set size\n",
    "print('Unlabeled Train Set:', X_unlab_p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d4b39",
   "metadata": {},
   "source": [
    "A `supervised` learning algorithm will only have 192 rows from which to train a model.\n",
    "\n",
    "A `semi-supervised` learning algorithm will have the 17174 labeled rows as well as the 17174 unlabeled rows that could be used in numerous ways to improve the labeled training dataset.\n",
    "\n",
    "Next, we can establish a baseline in performance on the semi-supervised learning dataset using a supervised learning algorithm fit only on the labeled training data.\n",
    "\n",
    "This is important because we would expect a semi-supervised learning algorithm to outperform a supervised learning algorithm fit on the labeled data alone. If this is not the case, then the semi-supervised learning algorithm does not have skill.\n",
    "\n",
    "In this case, we will use a `logistic regression` algorithm fit on the labeled portion of the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fb6c7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning ⚠ \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# libraries \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaling \n",
    "scale = StandardScaler().fit_transform(X_train,y)\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# fit model on labeled dataset\n",
    "model.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b7d61",
   "metadata": {},
   "source": [
    "The model can then be used to make predictions on the entire `Unlabeled` dataset and evaluated using classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a050e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on Unlabeled dataset\n",
    "yhat = model.predict_proba(X_unlab_p)\n",
    "label = model.predict(X_unlab_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f550fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b32437",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(yhat, columns=y[:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8bf143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum value predicted for each label\n",
    "maximum_value = df[df.columns].max(axis=1)\n",
    "maximum_value = pd.DataFrame(data=maximum_value, columns=['Maximum_value'])\n",
    "# dataframe of the predicted Label\n",
    "df_l = pd.DataFrame(data=label, columns=['Predicted Labels'])\n",
    "# DataFrame of the Maximum probabiliy of predicting each label and the Label that was predicted...\n",
    "df_la_max =pd.concat([df_l,maximum_value,df], axis=1)\n",
    "df_la_max.sample(frac=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization librarie\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('darkgrid')\n",
    "# distribution of the maximum value\n",
    "plt.hist(df_la_max['Maximum_value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85465b",
   "metadata": {},
   "source": [
    "Next, let’s explore how to apply the label propagation algorithm to the dataset.\n",
    "\n",
    "# Label Propagation for Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e364ff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from sklearn\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaling \n",
    "scale = StandardScaler().fit_transform(X_train,y)\n",
    "# define model\n",
    "model_ = LabelPropagation()\n",
    "# fit model on training dataset\n",
    "model_.fit(X_train,y)\n",
    "# make predictions on hold out test set\n",
    "yhat_ = model_.predict(X_unlab_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec268a64",
   "metadata": {},
   "source": [
    "Label Propagation algorithm in scikit-learn, let apply semi-supervised learning dataset.\n",
    "\n",
    "First, we must prepare the training dataset.\n",
    "\n",
    "We can concatenate the input data of the training dataset into a single array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48196381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_label = pd.concat([X_train,y],axis=1)\n",
    "X_test_unlabel = pd.concat([X_unlab_p,y_unlab], axis=1)\n",
    "X_train_label.shape, X_test_unlabel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training dataset input\n",
    "X_train_mixed = pd.concat([X_train_label, X_test_unlabel])\n",
    "X_train_mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c7592",
   "metadata": {},
   "source": [
    "We can then create a list of -1 valued (unlabeled) for each row in the unlabeled portion of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"no label\" for unlabeled data\n",
    "nolabel = [-1 for _ in range(len(y_unlab))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690a207",
   "metadata": {},
   "source": [
    "This list can then be concatenated with the labels from the labeled portion of the training dataset to correspond with the <br>input array for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca818fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "# recombine training dataset labels\n",
    "y_train_mixed = np.concatenate((le.transform(y), nolabel))\n",
    "y_train_mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c227a",
   "metadata": {},
   "source": [
    "We can now train the LabelPropagation model on the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_eval,y_train,y_eval = train_test_split(X_train_mixed.drop(labels='ICD', axis=1),y_train_mixed, random_state=41, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = LabelPropagation()\n",
    "# fit model on training dataset\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aab91b",
   "metadata": {},
   "source": [
    "Next, we can use the model to make predictions on the holdout dataset <br>\n",
    "and evaluate the model using classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d96e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels for entire training dataset data\n",
    "tran_labels = model.transduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c3642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86924393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
